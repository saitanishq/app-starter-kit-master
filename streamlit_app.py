import streamlit as st
import boto3
import json
import openai
from datetime import datetime

# Initialize AWS S3 client
s3_client = boto3.client('s3')

def read_json_from_s3(bucket, key):
    response = s3_client.get_object(Bucket=bucket, Key=key)
    return json.loads(response['Body'].read().decode('utf-8'))

def write_json_to_s3(data, bucket, key):
    s3_client.put_object(Bucket=bucket, Key=key, Body=json.dumps(data).encode('utf-8'))

def normalize_text(text):
    return text.lower().strip()

def get_most_similar_question(input_question, question_list, threshold):
    for question in question_list:
        if input_question in question:
            return question, 1.0  # Assuming perfect match for simplicity
    return None, 0

def generate_answer_with_gpt(question, context):
    openai_api_key = st.secrets["OPENAI_API_KEY"]
    prompt = f"{context}\n\nQuestion: {question}\nAnswer:"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message['content']

def get_next_filename(bucket, prefix):
    max_number = 0
    paginator = s3_client.get_paginator('list_objects_v2')
    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):
        for obj in page.get('Contents', []):
            filename = obj['Key'].split('/')[-1]
            parts = filename.split('-')
            number_part = parts[0][1:]
            if number_part.isdigit():
                number = int(number_part)
                if number > max_number:
                    max_number = number

    next_number = max_number + 1
    next_filename = f"f{next_number:03}-{datetime.now().strftime('%Y%m%d')}_qa.json"
    return next_filename

def search_question_in_bucket(question, bucket, prefix, similarity_threshold=0.9):
    questions = {}
    paginator = s3_client.get_paginator('list_objects_v2')
    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):
        for obj in page.get('Contents', []):
            data = read_json_from_s3(bucket, obj['Key'])
            normalized_question = normalize_text(data.get('q'))
            questions[normalized_question] = data.get('a')

    normalized_input_question = normalize_text(question)
    most_similar_question, similarity_score = get_most_similar_question(normalized_input_question, list(questions.keys()), similarity_threshold)

    if most_similar_question and similarity_score >= similarity_threshold:
        return True, questions[most_similar_question]
    else:
        context = "Provide information relevant to user queries based on previous knowledge."
        generated_answer = generate_answer_with_gpt(question, context)
        next_filename = get_next_filename(bucket, prefix)
        qa_data = {'q': question, 'a': generated_answer}
        write_json_to_s3(qa_data, bucket, f"{prefix}{next_filename}")
        return False, f"GPT-generated answer: {generated_answer}"

st.title('Health AI Davinci')

bucket_name = st.secrets["BUCKET_NAME"]
prefix = st.secrets["PREFIX"]

if "query_history" not in st.session_state:
    st.session_state.query_history = []

def add_query_to_history(question):
    st.session_state.query_history.append(question)

# Sidebar for question history
with st.sidebar:
    st.write("## Question History")
    for query in st.session_state.query_history:
        st.write(query)

question = st.text_input("Ask a question:", "")
if question:
    add_query_to_history(question)  # Add question to history
    with st.spinner('Searching for your answer...'):
        found, answer = search_question_in_bucket(question, bucket_name, prefix)
        if found:
            st.success("Found answer in the database:")
        else:
            st.success("Answer generated by GPT:")
        st.write(answer)
